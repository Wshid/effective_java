## [ITEM.48] 스트림 병렬화는 주의하여 적용

### 동시성 프로그래밍에서의 java
- 첫 릴리즈부터, `thread`, 동기화, `wait/notify` 지원
- java 5:
  - 동시성 컬렉션(`java.util.concurrent`) 라이브러리 지원
  - 실행자(**Executor) 프레임워크 지원
- java 7:
  - 고성능 병렬 분해(parallel decom-position) 프레임워크인
    - `fork-join` 패키지 추가
- java 8:
  - `parallel` 메서드만 한번 호출하면
    - **파이프라인**을 **병렬** 실행할 수 있는 `stream` 지원
- 동시성 프로그래밍에서 중요한 것
  - **안전성**(Safety)와 **응답 가능**(liveness) 상태 유지
  - **병렬 스트림 파이프라인 프로그래밍**에서도 중요

### parallel과 예시
- 스트림을 사용하여 첫 20개의 메르센 소수 생성
  ```java
  public static void main(String[] args) {
    primes().map(p -> TWO.pow(p.intValueExact()).subtract(ONE))
            .filter(mersenne -> mersenne.isProbablePrime(50))
            .limit(20)
            .forEach(System.out::println);
  }

  static Stream<BigInteger> primes() {
    return Stream.iterate(TWO, BigInteger::nextProbablePrime);
  }
  ```
  - 실행시 약 `12.5`초만에 완료
  - 속도를 높이기 위해 **스트림 파이프라인**의 `parallel()`을 호출한다면
    - 성능은?
- `parallel()`로 변경 호출 시
  - 프로그램은 아무것도 출력하지 못함
  - CPU 90%
  - 응답 불가 상태(liveness failure)

### liveness failure의 원인
- **스트림 라이브러리**가,
  - 이 파이프라인을 **병렬화**하는 방법을 찾지 못했기 때문
- 환경이 아무리 좋아도
  - 데이터 소스가 `Stream.iterate` 이거나
  - **중간 연산**으로 `limit`을 쓰면
  - **파이프라인 병렬화**로는 성능 개선을 기대할 수 없다.
- **파이프라인 병렬화**는 `limit`을 다룰때, cpu 코어가 남는다면
  - 원소를 몇개 더 처리한 이후, **제한된 개수 이후의 결과를 버려도** 아무런 해가 없다고 가정함
  - 위 예시의 경우
    - 새롭게 메르겐 소수를 찾을 때마다, 그 전 소수 찾을 때보다 2배정도 오래 걸림
    - `원소 하나를 계산하는 비용 = 그 이전까지의 원소 전부를 계산한 비용`
  - 이에 따라 파이프 병렬화 알고리즘이 정상 동작하지 못함

### 병렬 수행 효율 - 자료구조
- 스트림의 소스가
  - `ArrayList`, `HashMap`, `HashSet`, `ConcurrentHashMap`
    - 의 인스턴스이거나
  - **배열**, **int 범위**, **long 범위** 일때
  - 병렬화의 효과가 가장 좋다
- 이 자료구조들은
  - 데이터를 **원하는 크기로** 정확하고 쉽게 나눌 수 있어서
  - 일을 **다수의 스레드**에 **분배**하기 좋음
- 나누는 작업은 `Spliterator`가 담당하며
  - `Spliterator` 객체는
    - `Stream`이나 `Iterable::spliterator`로 얻어올 수 있음

### 참조 지역성
- 또한 해당 자료구조들은
  - 원소들을 순차적으로 실행시, **참조 지역성**(locality of reference)가 좋음
    - **이웃한 원소의 참조**들이 **메모리**에 **연속**해서 저장되어 있음
- **참조**들이 가리키는 실제 객체가, 메모리에서 떨어져 있을 수 있다
  - **참조 지역성이 나빠짐**
- 참조 지역성이 낮을 경우
  - **스레드**는 데이터가 **주 메모리**에서 **캐시 메모리**로 전송되어 오기를 기다리며
  - 대부분의 시간을 아무것도 하지 않음
- 참조 지역성은
  - 다량의 데이터를 처리하는 **벌크 연산을 병렬화**할 때 중요한 요소
- 참조 지역성이 가장 뛰어난 자료구조는
  - **기본 타입**의 **배열**
  - 기본 타입 배열에서는 **참조가 아닌** 데이터 자체가 메모리에 연속하여 저장되기 때문

### 병렬 수행 효율 - 종단 연산의 동작방식
- **종단 연산**에서 수행하는 작업량이
  - **파이프라인** 전체 작업에서 상당한 비중을 차지하면서, 순차적이라면
  - 효과는 **제한적**
- **종단 연산**중 병렬화에 효과적인 것은 `reduction`(축소) 연산
- 축소는
  - **파이프라인**에서 만들어진 모든 원소를 **하나로 합치는 작업**
  - `Stream`의 
    - `reduce` 메서드 중 하나
    - `min`, `max`, `count`, `sum` 같이 완성된 형태로 제공되는 메서드 중 하나를 선택해 수행
- `anyMatch`, `allMatch`, `noneMatch` 처럼
  - 조건에 맞으면 **바로 반환**되는 메서드도 병렬화에 적합
- 가변 축소(`mutable reduction`)을 수행하는
  - `Stream::collect`는 병렬화에 적합하지 않음
  - 컬렉션 합치는 비용이 높기때문

### 직접 구현한 인스턴스의 병렬화 이점 누리기
- 직접 구현한 `Stream`, `Iterable`, `Collection`이 병렬화의 이점을 누리려면
  - **`spliterator` 메서드를 반드시 재정의**
  - 결과 스트림의 **병렬화** 성능을 강도 높게 테스트
- 고효율 `spliterator`을 작성하는 것은 난이도 높은 작업

### 스트림을 잘못 병렬화할 경우
- **응답 불가**를 포함해 성능이 나빠질 뿐만 아니라
  - 결과 자체가 잘못되거나, 예상치 못한 동작 발생
- 안전 실패(`safety failure`)
  - 결과가 잘못되거나 오동작하는 경우
- 안전 실패는
  - 병렬화한 파이프라인이 사용하는 `mappers`, `filters` 또는 프로그래머가 제공한 다른 함수 객체가
    - 명세대로 동작하지 않을때 발생
- `Stream`명세는 이때 사용되는 **함수 객체**에 대한 규약 명시
  - `Stream`의 `reduce`연산에 건네지는 
    - `accumulator`와 `combiner` 함수는
    - **결합 법칙**(associative)을 만족하고
    - **간섭 받지 않고**(non-interfering)
    - **상태 x**(stateless)
  - 이상의 요구사항을 지키지 못하는 상태여도
    - 파이프라인을 **순차적으로** 수행시, 올바른 결과 얻기는 가능
    - **단, 병렬 수행시 문제 발생**

### 병렬화한 메르겐 소수 예시의 문제
- 프로그램이 완료 되더라도, 출력된 소수의 순서가 올바르지 않을 수 있음
- 출력 순서를 **순차 정렬**하고 싶다면
  - **종단 연산** `forEach` -> `forEachOrdered`로 변환
- `forEachOrdered`
  - 스트림을 순회하면서, 소수를 발견한 순서대로 출력되도록 보장

### 병렬화시 유의점
- 데이터 소스 스트림이 효율적으로 나눠지고,
  - 병렬화 하거나, 빨리끝나는 종단 연산을 사용하고
  - 함수 객체들도 간섭하지 않더라도
    - **파이프라인**이 수행하는 진짜 작업이 
      - **병렬화**에 드는 **추가 비용**을 상쇄하지 못한다면, 성능 향상은 미미함
- **성능 향상** 추정 방법
  - `스트림 안의 원소수 * 원소당 수행되는 코드 줄 수`
  - 이 값이 **최소 수십만**은 되어야 성능 향상 가능

### 병렬화 = 최적화 수단
- 병렬화는 오직 최적화 수단
- 변경 전후로, 반드시 **성능 테스트**하여 **병렬화**를 사용할 가치가 있는지 확인(ITEM.67)
- 이상적으로는
  - 운영 시스템과 흡사한 환경에서 테스트 하는것이 좋음
- **병렬 스트림 파이프라인**도
  - 공통의 **fork-join**풀에서 수행되므로(**동일한 thread-pool을 사용하므로**)
  - 잘못된 파이프라인 하나가, 다른 부분의 성능에까지 **악영향**을 줄 수 있음

### 스트림 병렬화 소요 및 효과
- 스트림 파이프라인을 병렬화할 일이 많지 않음
- 조건이 잘 갖춰지면, `parallel` 메서드 호출 하나로
  - 프로세서 코어 수에 비례하는 성능 향상 가능
- 예시
  - `π(n)`, `n`보다 작거나 같은 소수의 개수 계산
  ```java
  static long pi(long n) {
    return LongStream.rangeClosed(2, n)
                      .mapToObj(BigInteger::valueOf)
                      .filter(i -> i.isProbablePrime(50))
                      .count();
  }
  ```
  - `π(10^8)` 계산시, 31초 소요
  - `parallel` 사용시, 9.2초로 단축
  ```java
  static long pi(long n) {
    return LongStream.rangeClosed(2, n)
                      .parallel()
                      .mapToObj(BigInteger::valueOf)
                      .filter(i -> i.isProbablePrime(50))
                      .count();
  }
  ```
- 쿼드 코어를 장착한 컴퓨터에서, `3.37`배 연산속도 향상
- 하지만 `n`이 크다면 `π(n)`을 이방식으로 계산하는 것은 좋지 않음
  - 레머의 공식(`Lehmer's Formula`), 효율적인 알고리즘 존재

### 무작위 수로 이루어진 스트림의 병렬화(`SplittableRandom`)
- **무작위 수**들로 이루어진 스트림을 병렬화 하려면
  - `ThreadLocalRandom`또는 `Random` 인스턴스보다
    - `SplittableRandom` 인스턴스를 활용
- `SplittableRandom`은
  - 병렬화 하면, 성능이 **선형**으로 증가
- `ThreadLocalRandom`은 **단일 스레드**에서 쓰고자 만들어짐
  - 이 역시, 병렬 스트림용 데이터 소스로도 사용은 가능하나
    - `SplittableRandom`만큼 빠르지는 않음
- `Random`은 모든 연산을 **동기화**하기 때문에
  - 병렬 처리엔 최악


### 정리
- 계산도 올바로 수행하고, 성능이 빨라질 것이라는 확신 없이는
  - **스트림 파이프라인 병렬화**는 시도하지 말 것
- 병렬화를 잘못 수행할 경우
  - 프로그램 오동작, 성능 저하 발생
- 병렬화를 하였더라도,
  - 수정 후의 코드가 정확한지 확인
  - 운영 환경과 유사한 조건에서 수행, 성능 지표 관찰 필요
- 계산도 정확하고 성능도 좋아졌을 때
  - 병렬화를 운영 코드에 반영할 것